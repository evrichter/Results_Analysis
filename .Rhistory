correct_probes <- data.table(Item=seq(61,72), Correct=c(1, 7, 7, 1, 1, 7, 1, 1, 7, 1, 7, 7))
probes <- merge(probes, correct_probes, on=Item)
probes$Accurate <- probes$Rating == probes$Correct
probes$AccSum <- probes$Rating == probes$Correct
aggregate(Accurate ~ ID, probes, mean) # accurate proportion per ID
aggregate(Accurate ~ ID, probes, sum) # number / 12 correct per ID
# no participant answered more than 2 out of 12 attention checks wrong
# Checks for completeness / balancing / lists
table(dt$ID, dt$Item)        # Did every subject see each item once and only once
table(dt$ID, dt$Condition)   # Did each condition get presented to each subject the same amount of times (i.e. 10)
table(dt$Item, dt$Condition) # How often was each condition of each item presented
table(dt$list)               # How many trials were collected per list
dt_items <- dt[, lapply(.SD, mean), by=list(Item, Condition), .SDcols=c("Rating", "ReactionTime")]
#dt_items[,c("Rating_SD", "ReactionTime_SD")] <- dt[, lapply(.SD, sd), by=list(Item, Condition), .SDcols=c("Rating", "ReactionTime")][,c(3,4)]
dt_items[,c("Rating_SE", "ReactionTime_SE")] <- dt[, lapply(.SD, se), by=list(Item, Condition), .SDcols=c("Rating", "ReactionTime")][,c(3,4)]
cond <- dt_items[, lapply(.SD, mean), by=list(Condition), .SDcols=c("Rating", "ReactionTime")]
condse <- dt_items[, lapply(.SD, sd), by=list(Condition), .SDcols=c("Rating", "ReactionTime")]
cond <- merge(cond, condse, by="Condition", suffixes=c("", "_SE"))
cond
# ratings per item & condition sorted
stim <- dt_items[,lapply(.SD, mean), by=list(Item, Condition), .SDcols=c("Rating", "ReactionTime")]
dt[,lapply(.SD, mean), by=list(Item, Condition), .SDcols=c("Rating", "ReactionTime")]
condabc <- stim[Condition %in% c("A", "B", "C"),]
condd <- stim[Condition %in% c("Ad", "Bd", "Cd"),]
dt_items[order(dt_items),]
stim[order(stim$Item),]
condabc[order(condabc$Item),]
condd[order(condd$Item),]
items <- data.frame(condabc[order(data.frame(condabc)[,1], data.frame(condabc)[,2])])
items[,c("Ratingdist", "ReactionTimedist")] <- data.frame(condd[order(data.frame(condd)[,1], data.frame(condd)[,2])])[,c("Rating", "ReactionTime")]
fwrite(data.table(items), "plausresults.csv")
# (after doing the switcheroo on the conditions / target words)
# dt <- fread("GradedP6_results.csv")
dt <- fread("plausresults.csv")
# calculate average plausibility per condition
avg_condition_target <- aggregate(Rating ~ Condition, data = dt, FUN = "mean")
avg_condition_target
avg_condition_dist <- aggregate(Ratingdist ~ Condition, data = dt, FUN = "mean")
avg_condition_dist
# calculate sd per condition
sd_condition_target <- aggregate(Rating ~ Condition, data = dt, FUN = "sd")
sd_condition_target
sd_condition_dist <- aggregate(Ratingdist ~ Condition, data = dt, FUN = "sd")
sd_condition_dist
# calculate range per condition
range_condition_target <- aggregate(Rating ~ Condition, data = dt, FUN = "range")
range_condition_target
range_condition_dist <- aggregate(Ratingdist ~ Condition, data = dt, FUN = "range")
range_condition_dist
#condd <- dt_items[, lapply(.SD, mean), by=list(Condition), .SDcols=c("Plaus_distractor")]
#condd <- dt[, lapply(.SD, mean), by=list(Condition), .SDcols=c("Plaus_distractor")]
##### PLAUS DATA VIZ #####
library(ggplot2)
library(gridExtra)
### PLAUSIBILITY ###
# density plot target
means <- aggregate(Rating ~ Condition, dt, FUN=mean)
means$Plaus_SE <- aggregate(Rating ~ Condition, dt, FUN=se)$Rating
dt_items_abc <- dt[, lapply(.SD, mean), by=list(Item, Condition), .SDcols=c("Rating")]
p1 <- ggplot(dt_items_abc, aes(x=Rating, color=Condition, fill=Condition)) + geom_density(alpha=0.4) + theme_minimal() + ylim(0, 3)
p1 <- p1 + geom_vline(data=means, aes(xintercept=Rating, color=Condition), linetype="dashed") + scale_x_continuous(breaks=seq(1,7))
p1 <- p1 + scale_color_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
p1 <- p1 + scale_fill_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
p1 <- p1 + labs(title = "Target Plausibility", y="Density", x= "Rating") + theme(legend.position = "none") + theme(plot.title = element_text(hjust = 0.5))
ggsave("DensityPlot_Plausibility_Target.pdf", p1, device=cairo_pdf, width=4, height=4)
p1
# barplot target
q1 <- ggplot(means, aes(x=Condition, y=Rating)) + geom_bar(stat="identity") + labs(title = "Average Plausibility Ratings per Condition (Target)", y = "Plausibility", x = "Condition") + geom_errorbar(aes(ymin=Rating-Plaus_SE, ymax=Rating+Plaus_SE), width=.4, position=position_dodge(.9)) + theme_minimal() + coord_cartesian(ylim = c(1, 7)) + scale_y_continuous(breaks = c(1:7))
ggsave("BarPlot_Plausibility_Target.pdf", q1, device=cairo_pdf, width=4, height=4)
q1
# density plot distractor
means <- aggregate(Ratingdist ~ Condition, dt, FUN=mean)
means$Plaus_distractor_SE <- aggregate(Ratingdist ~ Condition, dt, FUN=se)$Ratingdist
dt_items_d <- dt[, lapply(.SD, mean), by=list(Item, Condition), .SDcols=c("Ratingdist")]
p2 <- ggplot(dt_items_d, aes(x=Ratingdist, color=Condition, fill=Condition)) + geom_density(alpha=0.4) + theme_minimal() + ylim(0, 1)
p2 <- p2 + geom_vline(data=means, aes(xintercept=Ratingdist, color=Condition), linetype="dashed") + scale_x_continuous(breaks=seq(1,7))
p2 <- p2 + scale_color_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
p2 <- p2 + scale_fill_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
p2 <- p2 + labs(title = "Distractor Plausibility", y = "Density", x="Rating") + theme(legend.position = "none") + theme(plot.title = element_text(hjust = 0.5))
ggsave("DensityPlot_Plausibility_Distractor.pdf", p2, device=cairo_pdf, width=4, height=4)
p2
# barplot distractor
q2 <- ggplot(means, aes(x=Condition, y=Ratingdist)) + geom_bar(stat="identity") + labs(title = "Average Plausibility Ratings per Condition (Distractor)", y = "Plausibility", x = "Condition") + geom_errorbar(aes(ymin=Ratingdist-Plaus_distractor_SE, ymax=Ratingdist+Plaus_distractor_SE), width=.4, position=position_dodge(.9)) + theme_minimal() + coord_cartesian(ylim = c(1, 7)) + scale_y_continuous(breaks = c(1:7))
ggsave("BarPlot_Plausibility_Distractor.pdf", q2, device=cairo_pdf, width=4, height=4)
q2
#### SURPRISAL ###
#setwd("~/Downloads/Master_Thesis/2_Surprisal_Values")
#dt <- fread("FollowUp_GPT2_surprisals_edited.csv")
#dt <- dt[!(Surprisal_Target %in% NA & Surprisal_Distractor %in% NA),]
# density plot target
#means <- aggregate(Surprisal_Target ~ Condition, dt, FUN=mean)
#means$Plaus_SE <- aggregate(Surprisal_Target ~ Condition, dt, FUN=se)$Surprisal_Target
#dt_items_abc2 <- dt[, lapply(.SD, mean), by=list(Item, Condition), .SDcols=c("Surprisal_Target")]
#p3 <- ggplot(dt_items_abc2, aes(x=Surprisal_Target, color=Condition, fill=Condition)) + geom_density(alpha=0.4) + theme_minimal() + coord_cartesian(xlim = c(1, 22)) + ylim(0, 0.5)
#p3 <- p3 + geom_vline(data=means, aes(xintercept=Surprisal_Target, color=Condition), linetype="dashed") + scale_x_continuous(breaks=seq(0, 22, by = 2))
#p3 <- p3 + scale_color_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
#p3 <- p3 + scale_fill_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
#p3 <- p3 + labs(title = "Target Surprisal", y="Density", x= "Surprisal") + theme(legend.position = "none") + theme(plot.title = element_text(hjust = 0.5))
#ggsave("DensityPlot_Surprisal_Target.pdf", p3, device=cairo_pdf, width=4, height=4)
#p3
# density plot distractor
#means <- aggregate(Surprisal_Distractor ~ Condition, dt, FUN=mean)
#means$Plaus_distractor_SE <- aggregate(Surprisal_Distractor ~ Condition, dt, FUN=se)$Surprisal_Distractor
#dt_items_d <- dt[, lapply(.SD, mean), by=list(Item, Condition), .SDcols=c("Surprisal_Distractor")]
#p4 <- ggplot(dt_items_d, aes(x=Surprisal_Distractor, color=Condition, fill=Condition)) + geom_density(alpha=0.4) + theme_minimal() + ylim(0, 0.5)
#p4 <- p4 + geom_vline(data=means, aes(xintercept=Surprisal_Distractor, color=Condition), linetype="dashed") + scale_x_continuous(breaks=seq(0, 22, by = 2))
#p4 <- p4 + scale_color_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
#p4 <- p4 + scale_fill_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
#p4 <- p4 + labs(title = "Distractor Surprisal", y = "Density", x="Surprisal") + theme(legend.position = "none") + theme(plot.title = element_text(hjust = 0.5))
#ggsave("DensityPlot_Surprisal_Distractor.pdf", p4, device=cairo_pdf, width=4, height=4)
#p4
### COMBINED PLOT ###
#combined_plot <- grid.arrange(p1, p3, p2, p4, ncol = 2)  # Replace p1, p2, p3, and p4 with your ggplot objects
#setwd("~/Downloads/Master_Thesis/1_Plausibility_Rating_Study/")
#dt <- fread("plausresults.csv")
# plot1 with legend
#means <- aggregate(Rating ~ Condition, dt, FUN=mean)
#means$Plaus_SE <- aggregate(Rating ~ Condition, dt, FUN=se)$Rating
#dt_items_abc <- dt[, lapply(.SD, mean), by=list(Item, Condition), .SDcols=c("Rating")]
#plot1_legend <- ggplot(dt_items_abc, aes(x=Rating, color=Condition, fill=Condition)) + geom_density(alpha=0.4) + theme_minimal() + ylim(0, 1.5)
#plot1_legend <- plot1_legend + geom_vline(data=means, aes(xintercept=Rating, color=Condition), linetype="dashed") + scale_x_continuous(breaks=seq(1,7))
#plot1_legend <- plot1_legend + scale_color_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
#plot1_legend <- plot1_legend + scale_fill_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
#plot1_legend <- plot1_legend + labs(title = "Target Plausibility", y="Density", x= "Rating") + theme(legend.position = "bottom")
# function to extract legend from plot
#get_only_legend <- function(plot) {
#  plot_table <- ggplot_gtable(ggplot_build(plot))
#  legend_plot <- which(sapply(plot_table$grobs, function(x) x$name) == "guide-box")
#  legend <- plot_table$grobs[[legend_plot]]
#  return(legend)
#}
# extract legend from plot1 using above function
#legend <- get_only_legend(plot1_legend)
#combined_plot_with_legend <- grid.arrange(combined_plot, legend, nrow = 2, heights = c(10, 1))
#combined_plot_with_legend
# Save the combined plot
#ggsave("Combined_Plot.pdf", combined_plot_with_legend, device = "pdf")
# Attic
# dt[time >= 1634206744 & time < 1634206857,"ID"] <- "Square0"
# dt[time >= 1634206857 & time < 1634206952,"ID"] <- "Square1"
# dt[time >= 1634206952 & time < 1634207069,"ID"] <- "Square2"
# dt[time >= 1634207069 & time < 1634207161,"ID"] <- "Square3"
# dt[time >= 1634207161 & time < 1634207248,"ID"] <- "Square4"
# dt[time >= 1634207248 & time < 1634210796,"ID"] <- "Square5"
# dt[time >= 1634207248 & time < 1634210796,"ID"] <- "Square5"
# dt[time >= 1634211007 & time < 1634211093,"ID"] <- "Nummer3"
# dt <- dt[ID %in% c("Square0", "Square1", "Square2", "Square3", "Square4", "Square5", "Nummer3"),]
# include only values where A= 6,7 and B= 3,4,5 and C = 1,2
filtered_dt <- dt[(Condition=="A" & (Rating==6 | Rating==7)) |
(Condition=="B" & (Rating==3 | Rating==4 | Rating==5)) |
(Condition=="C" & (Rating==1 | Rating==2)) |
Condition %in% c("Ad","Bd","Cd"),]
View(filtered_dt)
# Ratings
dt <- fread("rating.txt")
# colnames(dt) <- c("time", "ID", "controller", "four", "Condition", "Item", "text", "Rating", "nine", "ReactionTime")
colnames(dt) <- c("time", "ID", "controller", "four", "five", "Condition", "Item", "text", "Rating", "nine", "ReactionTime")
dt[,c("controller", "four", "text", "nine")] <- NULL
dt <- dt[time > 1634211007,]
dt <- dt[!(ID %in% excluded_participants),]
probes <- dt[Condition=="P",]
dt <- dt[Condition != "P",]
# include only values where A= 6,7 and B= 3,4,5 and C = 1,2
filtered_dt <- dt[(Condition=="A" & (Rating==6 | Rating==7)) |
(Condition=="B" & (Rating==3 | Rating==4 | Rating==5)) |
(Condition=="C" & (Rating==1 | Rating==2)) |
Condition %in% c("Ad","Bd","Cd"),]
View(filtered_dt)
library(data.table)
# functions
se <- function(
x,
na.rm = FALSE
){
if (na.rm == TRUE) {
sd(x, na.rm=TRUE)/sqrt(length(x[!is.na(x)]))
} else {
sd(x)/sqrt(length(x))
}
}
assign_lists <- function(dt) {
l1 <- dt[(Item == 1 & Condition == "A"),]$ID
l2 <- dt[(Item == 1 & Condition == "B"),]$ID
l3 <- dt[(Item == 1 & Condition == "C"),]$ID
l4 <- dt[(Item == 1 & Condition == "Ad"),]$ID
l5 <- dt[(Item == 1 & Condition == "Bd"),]$ID
l6 <- dt[(Item == 1 & Condition == "Cd"),]$ID
print(nrow(dt))
dt$list <- rep(0, nrow(dt))
dt[ID %in% l1,"list"] <- 1
dt[ID %in% l2,"list"] <- 2
dt[ID %in% l3,"list"] <- 3
dt[ID %in% l4,"list"] <- 4
dt[ID %in% l5,"list"] <- 5
dt[ID %in% l6,"list"] <- 6
dt
}
setwd("~/Downloads/Master_Thesis/Plausibility_Rating_Exp/Avg_Plaus/")
excluded_participants <- c("de5b35d54ab253562f33dbc220ce6ad1",
"2f3782f686d1994ea4a1aad5bc820ab6",
"df5a38a1a27c50a04e3f1b94eb0b2fa5",
"ec29f1a573fc71d127f3cf69bdfd761e",
"18cd916fc4c15ff5b1ce21dab6af7c67",
"43c15b8013a137c690185b798ed67b0a")
# Demog
demog <- fread("demog.txt")
# colnames(demog) <- c("time", "ID", "three", "four", "five", "six", "question", "answer")
colnames(demog) <- c("time", "ID", "three", "four", "five", "six", "seven", "question", "answer")
demog[,c("three", "four", "five", "six")] <- NULL
demog <- dcast(demog, time + ID ~ question, value.var="answer")
demog <- demog[time > 1634211007,]
demog <- demog[!(ID %in% excluded_participants),]
# consent
consent <- fread("consent.txt")
# colnames(consent) <- c("time", "ID", "three", "four", "five", "six", "question", "answer")
colnames(consent) <- c("time", "ID", "three", "four", "five", "six", "seven", "question", "answer")
consent <- consent[time > 1634211007,]
consent <- consent[!(ID %in% excluded_participants),]
# Ratings
dt <- fread("rating.txt")
# colnames(dt) <- c("time", "ID", "controller", "four", "Condition", "Item", "text", "Rating", "nine", "ReactionTime")
colnames(dt) <- c("time", "ID", "controller", "four", "five", "Condition", "Item", "text", "Rating", "nine", "ReactionTime")
dt[,c("controller", "four", "text", "nine")] <- NULL
dt <- dt[time > 1634211007,]
dt <- dt[!(ID %in% excluded_participants),]
probes <- dt[Condition=="P",]
dt <- dt[Condition != "P",]
# include only values where A= 6,7 and B= 3,4,5 and C = 1,2
filtered_dt <- dt[(Condition=="A" & (Rating==6 | Rating==7)) |
(Condition=="B" & (Rating==3 | Rating==4 | Rating==5)) |
(Condition=="C" & (Rating==1 | Rating==2)) |
Condition %in% c("Ad","Bd","Cd"),]
dt <- assign_lists(filtered_dt)
# Probes
correct_probes <- data.table(Item=seq(61,72), Correct=c(1, 7, 7, 1, 1, 7, 1, 1, 7, 1, 7, 7))
View(filtered_dt)
probes <- dt[Condition=="P",]
# Ratings
dt <- fread("rating.txt")
# colnames(dt) <- c("time", "ID", "controller", "four", "Condition", "Item", "text", "Rating", "nine", "ReactionTime")
colnames(dt) <- c("time", "ID", "controller", "four", "five", "Condition", "Item", "text", "Rating", "nine", "ReactionTime")
dt[,c("controller", "four", "text", "nine")] <- NULL
dt <- dt[time > 1634211007,]
dt <- dt[!(ID %in% excluded_participants),]
probes <- dt[Condition=="P",]
View(probes)
dt <- dt[Condition != "P",]
View(dt)
### PACKAGES
library(ggplot2)
library(data.table)
library(gridExtra)
library(dplyr)
setwd("~/Downloads/Master_Thesis/Plausibility_Rating_Exp/Avg_Plaus/")
source("ibex_fns.r")
#### DATA FORMATTING
# Get DEMOG CONSENT SURVEY data
cn <- get_consent("consent.txt")
dm <- get_demog("demog.txt")
debugSource("~/Downloads/Master_Thesis/Plausibility_Rating_Exp/Avg_Plaus/read_ibex.r")
View(dt)
### PACKAGES
library(ggplot2)
library(data.table)
library(gridExtra)
library(dplyr)
setwd("~/Downloads/Master_Thesis/Plausibility_Rating_Exp/Avg_Plaus/")
source("ibex_fns.r")
#### DATA FORMATTING
# Get DEMOG CONSENT SURVEY data
cn <- get_consent("consent.txt")
dm <- get_demog("demog.txt")
sv <- get_survey("survey.txt")
survey <- merge(dm, sv, by=c("IPhash"), all=TRUE)
survey$Age <- as.numeric(survey$Age)
round(mean(survey$Age),2)
round(sd(survey$Age),2)
range(survey$Age)
table(survey$gender)
nrow(survey[!(Native_language %in% c("Deutsch", "deutsch")),])
table(survey$Task_difficulty)/length(survey$Task_difficulty)
table(survey$Experiment_length)/length(survey$Experiment_length)
table(survey$handedness)
# Get REACTION TIMES & READING TIMES
rc <- get_reacts("task.txt")
pr <- get_plausibility_rating("task.txt")
rd <- get_reads("reading.txt")
df <- merge(rd, rc[,c("ReactionTime", "Accuracy", "IPhash", "Item")], by=c("IPhash", "Item"), all=TRUE)
df <- merge(df, pr[,c("IPhash", "Item", "Condition", "SPR_Plaus_Rating", "SPR_Plaus_avg")], by=c("IPhash", "Item", "Condition"), all=TRUE)
# Change IPhashes to subject numbers
colnames(df)[1] <- "Subject"
df[, Subject := .GRP, by = .(Subject)]
df$Subject <- as.character(df$Subject)
# merge df with assoc plausibility and surprisal values in pretests
pretests <- fread("plausresults.csv")
df <- merge(df, pretests[,c("Item", "Condition", "Verb", "Target", "Distractor", "Last_Mentioned", "Plaus_target_avg", "Plaus_dist_avg", "Surprisal_target", "Surprisal_distractor")], by=c("Item", "Condition"))
# add precritRT as predictor
df$precritRT <- rep(df[Region=="Pre-critical",]$ReadingTime, each=5)
# change column order
df <- df %>% relocate(precritRT, .before= ReadingTime)
# save merged files in new csv file
fwrite(df, "GP6SPR.csv")
View(df)
# merge df with assoc plausibility and surprisal values in pretests
pretests <- fread("plausresults.csv")
df <- merge(df, pretests[,c("Plaus_target_avg", "Plaus_dist_avg", "Surprisal_target", "Surprisal_distractor")], by=c("Item", "Condition"))
# merge df with assoc plausibility and surprisal values in pretests
pretests <- fread("plausresults.csv")
df <- merge(df, pretests[,c("Rating", "Ratingdist")], by=c("Item", "Condition"))
View(df)
# merge df with assoc plausibility and surprisal values in pretests
pretests <- fread("plausresults.csv")
df <- merge(df, pretests[,c("Item", "Condition", "Rating", "Ratingdist")], by=c("Item", "Condition"))
# add precritRT as predictor
df$precritRT <- rep(df[Region=="Pre-critical",]$ReadingTime, each=5)
# change column order
df <- df %>% relocate(precritRT, .before= ReadingTime)
# save merged files in new csv file
fwrite(df, "GP6SPR.csv")
### REMOVING OUTLIERS IN READING TIME AND REACTION TIME DATA
# Remove too high or low reading times and reaction times
df <- remove_outliers(df)
fwrite(df, "GP6SPR_processed.csv")
##### CHECK ACCURACIES AND READING TIMES #####
# saved df into GP6 csv file because when reading GP6 from the scratch it cannot be processed by the following functions
# GP6 <- read.csv("GP6SPR_processed.csv")
GP6 <- df
# Check mean accuracies / mean reaction times PER PARTICIPANT
###calculate mean Reaction Time and Accuracy per subject ### just for info, is not included in thesis
# removed rows where reaction time was NA, because otherwise the lapply method includes them in the mean calculation which makes the mean lower
GP6 <- GP6[!(ReactionTime %in% c(NA)),] #remove rows
GP6 <- GP6[, lapply(.SD, mean, na.rm = TRUE), by=Subject, .SDcols=c("ReactionTime", "Accuracy")] #mean of accuracy and reaction time per subject
GP6$Subject <- as.factor(GP6$Subject)
GP6[order(GP6$ReactionTime),] #grouped  by reaction time
GP6[order(GP6$Accuracy),] # grouped by accuracy
# calculate mean accuracy and mean reaction time OF ALL PARTICIPANTS (based on rows containing reaction times and accuracy)
mean_accuracy <- mean(GP6$Accuracy, na.rm = TRUE)
cat("Mean Accuracy:", as.numeric(mean_accuracy))
mean_RT <- mean(GP6$ReactionTime, na.rm = TRUE)
cat("Mean Reaction Time:", as.numeric(mean_RT))
# calculate sd of accuracy and sd of reaction time of all participants
sd_accuracy <- sd(GP6$Accuracy, na.rm = TRUE)
cat("SD:", as.numeric(sd_accuracy))
sd_RT <- sd(GP6$ReactionTime, na.rm = TRUE)
cat("SD:", as.numeric(sd_RT))
# calculate range of accuracy and range of reaction time of all participants
range_accuracy <- range(GP6$Accuracy, na.rm = TRUE)
cat("Minimum value:", as.numeric(range_accuracy[1]), "\n")
cat("Maximum value:", as.numeric(range_accuracy[2]), "\n")
range_RT <- range(GP6$ReactionTime, na.rm = TRUE)
cat("Minimum value:", as.numeric(range_RT[1]), "\n")
cat("Maximum value:", as.numeric(range_RT[2]), "\n")
# calculate mean accuracies and mean reaction times PER PARTICIPANT AND CONDITION
#again rename df into GP6 because loading the GP6 csv file causes an error
#GP6 <- read.csv("GP6SPR_processed.csv")
GP6 <- df
GP6 <- GP6[!(ReactionTime %in% c(NA)),] #remove rows containing NA for reaction time and accuracy
conditions <- c("A", "B", "C")
for (condition in conditions)
{
GP6_per_condition <- GP6[(Condition %in% c(condition)),] #subset condition
GP6_per_condition <- GP6_per_condition[, lapply(.SD, mean, na.rm = TRUE), by=Subject, .SDcols=c("ReactionTime", "Accuracy")]
GP6_per_condition[order(GP6_per_condition$ReactionTime),] #grouped  by reaction time
GP6_per_condition[order(GP6_per_condition$Accuracy),] # grouped by accuracy
#caclulate mean reaction time and accuracy per condition
mean_accuracy <- mean(GP6_per_condition$Accuracy, na.rm = TRUE)
cat("Mean Accuracy:", as.numeric(mean_accuracy), "\n")
mean_RT <- mean(GP6_per_condition$ReactionTime, na.rm = TRUE)
cat("Mean Reaction Time:", as.numeric(mean_RT), "\n")
#calculate sd of accuracy and sd of reaction time of all participants
sd_accuracy <- sd(GP6_per_condition$Accuracy, na.rm = TRUE)
cat("SD:", as.numeric(sd_accuracy), "\n")
sd_RT <- sd(GP6_per_condition$ReactionTime, na.rm = TRUE)
cat("SD:", as.numeric(sd_RT), "\n")
# calculate range of accuracy and range of reaction time of all participants
range_accuracy <- range(GP6_per_condition$Accuracy, na.rm = TRUE)
cat("Minimum value:", as.numeric(range_accuracy[1]), "\n")
cat("Maximum value:", as.numeric(range_accuracy[2]), "\n")
range_RT <- range(GP6_per_condition$ReactionTime, na.rm = TRUE)
cat("Minimum value:", as.numeric(range_RT[1]), "\n")
cat("Maximum value:", as.numeric(range_RT[2]), "\n")
}
# calculate MEAN PLAUSIBILITY RATINGS per condition [after removing outliers]
GP6 <- df
# include only values where A= 6,7 and B= 3,4,5 and C = 1,2
GP6 <- GP6[(Condition=="A" & (SPR_Plaus_Rating==6 | SPR_Plaus_Rating==7)) |
(Condition=="B" & (SPR_Plaus_Rating==3 | SPR_Plaus_Rating==4 | SPR_Plaus_Rating==5)) |
(Condition=="C" & (SPR_Plaus_Rating==1 | SPR_Plaus_Rating==2)),]
plaus_averages_by_condition <- aggregate(SPR_Plaus_avg ~ Condition, GP6, FUN = mean)
plaus_averages_by_condition
plaus_sd_by_condition <- aggregate(SPR_Plaus_avg ~ Condition, GP6, FUN = sd)
plaus_sd_by_condition
plaus_range_by_condition <- aggregate(SPR_Plaus_avg ~ Condition, GP6, FUN = range)
plaus_range_by_condition
#log transform reading times and add them as new column to GP6
GP6$logRT <- log(GP6$ReadingTime)
avg_logRT_by_regions_and_conditions <- data.frame(
Region = character(0),
Condition = character(0),
MeanReadingTime = numeric(0),
SE_MeanReadingTime = numeric(0)
)
regions <- c("Pre-critical", "Critical", "Spillover", "Post-spillover")
conditions <- c("A", "B", "C")
averages <- GP6 %>%
group_by(Region, Condition) %>%
summarise(
MeanReadingTime = mean(logRT, na.rm = TRUE),
SE = sd(logRT, na.rm = TRUE) / sqrt(n()))
# Print the resulting averages
print(averages)
# Exclude Pre-critical_2
averages <- averages %>%
filter(Region != "Pre-critical_2")
print(averages)
# Create a line plot with average log-transformed reading times
p <- ggplot(averages, aes(x = factor(Region, levels = c("Pre-critical", "Critical", "Spillover", "Post-spillover")),
y = MeanReadingTime, color = Condition, group = Condition)) + geom_point(shape = 4, size = 3.5, stroke = 0.8) + geom_line(linewidth=0.5) + ylim (5.5, 5.7)
p <- p + theme_minimal() + geom_errorbar(aes(ymin= MeanReadingTime-SE, ymax=MeanReadingTime+SE), width=.1, size=0.5)
p <- p + scale_color_manual(name="Condition", labels=c("A: Plausible", "B: Medium Plausible", "C: Implausible"), values=c("#000000", "#FF0000", "#0000FF"))
p <- p + theme(legend.position="bottom", legend.text=element_text(size=7), legend.title=element_text(size=7), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14))
p <- p + labs(x="Region", y="logRT", title = "Observed RTs")
p
ggsave("Observed_RTs_Plot.pdf", p, width=4, height=4)
# CALCULARE CORRELATIONS
# correlation avg Plaus per item and condition & suprisal from Plaus study
GP6 <- read.csv("GP6SPR.csv")  #use unprocessed file bc in prestudies no outliers based on RTs were removed yet
correlation_matrix <- cor(GP6[, c("Plaus_target_avg", "Plaus_dist_avg", "Surprisal_target", "Surprisal_distractor")])
correlation_matrix
# correlation svg Plaus per item and condition & surprisal from SPR study
# no plausibility distractor column, bc no distractor values were calculated for plausibility in the SPR study
correlation_matrix <- cor(GP6[, c("SPR_Plaus_Rating", "Surprisal_target", "Surprisal_distractor")])
correlation_matrix
# calculate correlation coefficient between SPR_Plaus_avg (avg Plausratings from SPR study) and Plaus_target_avg (avg Plausratings from Plaus study)
correlation <- cor(GP6$SPR_Plaus_avg, GP6$Plaus_target_avg)
cat("Correlation between SPR_Plaus_avg and Plaus_target_avg:", correlation)
# #### DATA VISUALISATION
# Data Viz for avg Plausratings from SPR Study
library(ggplot2)
setwd("~/Downloads/Master_Thesis/3_SPR_Study/Results_SPR_Plaus_single/")
dt <- fread("GP6SPR_processed.csv") #plots plausratings after removing outliers
means <- aggregate(SPR_Plaus_avg ~ Condition, dt, FUN=mean)
means$Plaus_SE <- aggregate(SPR_Plaus_avg ~ Condition, dt, FUN=se)$SPR_Plaus_avg
dt_items_abc <- dt[, lapply(.SD, mean), by=list(Item, Condition), .SDcols=c("SPR_Plaus_avg")]
# density plot plausibility SPR
p <- ggplot(dt_items_abc, aes(x=SPR_Plaus_avg, color=Condition, fill=Condition)) + geom_density(alpha=0.4) + theme_minimal() + xlim(1,7) + ylim(0, 1.5)
p <- p + geom_vline(data=means, aes(xintercept=SPR_Plaus_avg, color=Condition), linetype="dashed") + scale_x_continuous(breaks=seq(1,7))
p <- p + scale_color_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
p <- p + scale_fill_manual(labels=c("A", "B", "C"), values=c("black", "red", "blue"))
p <- p + labs(title = "Target Plausibility (SPR)", y="Density", x="Plausibility" ) + theme(legend.position = "bottom") + theme(plot.title = element_text(hjust = 0.5))
ggsave("DensityPlot_Plausibility_SPR.pdf", p, device=cairo_pdf, width=4, height=4)
p
# merge df with assoc plausibility and surprisal values in pretests
pretests <- fread("plausresults.csv")
df <- merge(df, pretests[,c("Item", "Condition", "Rating", "Ratingdist")], by=c("Item", "Condition"))
#### DATA FORMATTING
# Get DEMOG CONSENT SURVEY data
cn <- get_consent("consent.txt")
dm <- get_demog("demog.txt")
sv <- get_survey("survey.txt")
survey <- merge(dm, sv, by=c("IPhash"), all=TRUE)
survey$Age <- as.numeric(survey$Age)
round(mean(survey$Age),2)
round(sd(survey$Age),2)
range(survey$Age)
table(survey$gender)
nrow(survey[!(Native_language %in% c("Deutsch", "deutsch")),])
table(survey$Task_difficulty)/length(survey$Task_difficulty)
table(survey$Experiment_length)/length(survey$Experiment_length)
table(survey$handedness)
# Get REACTION TIMES & READING TIMES
rc <- get_reacts("task.txt")
pr <- get_plausibility_rating("task.txt")
rd <- get_reads("reading.txt")
df <- merge(rd, rc[,c("ReactionTime", "Accuracy", "IPhash", "Item")], by=c("IPhash", "Item"), all=TRUE)
df <- merge(df, pr[,c("IPhash", "Item", "Condition", "SPR_Plaus_Rating", "SPR_Plaus_avg")], by=c("IPhash", "Item", "Condition"), all=TRUE)
# Change IPhashes to subject numbers
colnames(df)[1] <- "Subject"
df[, Subject := .GRP, by = .(Subject)]
df$Subject <- as.character(df$Subject)
# merge df with assoc plausibility and surprisal values in pretests
pretests <- fread("plausresults.csv")
df <- merge(df, pretests[,c("Item", "Condition", "Rating", "Ratingdist")], by=c("Item", "Condition"))
# add precritRT as predictor
df$precritRT <- rep(df[Region=="Pre-critical",]$ReadingTime, each=5)
# change column order
df <- df %>% relocate(precritRT, .before= ReadingTime)
# save merged files in new csv file
fwrite(df, "GP6SPR.csv")
### REMOVING OUTLIERS IN READING TIME AND REACTION TIME DATA
# Remove too high or low reading times and reaction times
df <- remove_outliers(df)
fwrite(df, "GP6SPR_processed.csv")
#### DATA FORMATTING
# Get DEMOG CONSENT SURVEY data
cn <- get_consent("consent.txt")
dm <- get_demog("demog.txt")
sv <- get_survey("survey.txt")
survey <- merge(dm, sv, by=c("IPhash"), all=TRUE)
survey$Age <- as.numeric(survey$Age)
round(mean(survey$Age),2)
round(sd(survey$Age),2)
range(survey$Age)
table(survey$gender)
nrow(survey[!(Native_language %in% c("Deutsch", "deutsch")),])
table(survey$Task_difficulty)/length(survey$Task_difficulty)
table(survey$Experiment_length)/length(survey$Experiment_length)
table(survey$handedness)
# Get REACTION TIMES & READING TIMES
rc <- get_reacts("task.txt")
pr <- get_plausibility_rating("task.txt")
rd <- get_reads("reading.txt")
